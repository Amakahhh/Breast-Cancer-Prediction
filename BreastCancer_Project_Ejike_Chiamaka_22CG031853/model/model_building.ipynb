{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d85835f",
   "metadata": {},
   "source": [
    "# Breast Cancer Prediction System - Model Development\n",
    "## Support Vector Machine (SVM) Classification\n",
    "**Selected Features:** radius_mean, texture_mean, area_mean, smoothness_mean, compactness_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406e065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('✓ Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f27d626e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset loaded successfully\n",
      "Dataset shape: (569, 30)\n",
      "Target distribution:\n",
      "diagnosis\n",
      "1    357\n",
      "0    212\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Available features:\n",
      "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# Load the Breast Cancer Wisconsin dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = pd.Series(cancer.target, name='diagnosis')\n",
    "\n",
    "print('✓ Dataset loaded successfully')\n",
    "print(f'Dataset shape: {X.shape}')\n",
    "print(f'Target distribution:\\n{y.value_counts()}')\n",
    "print(f'\\nAvailable features:\\n{list(X.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de085f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: DATA PREPROCESSING - Missing Values Check\n",
      "==================================================\n",
      "Missing values in X: 0\n",
      "Missing values in y: 0\n",
      "✓ No missing values detected\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check for missing values\n",
    "print('STEP 1: DATA PREPROCESSING - Missing Values Check')\n",
    "print('='*50)\n",
    "missing_X = X.isnull().sum().sum()\n",
    "missing_y = y.isnull().sum()\n",
    "print(f'Missing values in X: {missing_X}')\n",
    "print(f'Missing values in y: {missing_y}')\n",
    "if missing_X == 0 and missing_y == 0:\n",
    "    print('✓ No missing values detected')\n",
    "else:\n",
    "    print('✗ Missing values found - handling required')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa12889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 2: FEATURE SELECTION\n",
      "==================================================\n",
      "Selected 5 features: ['mean radius', 'mean texture', 'mean area', 'mean smoothness', 'mean compactness']\n",
      "Feature matrix shape: (569, 5)\n",
      "\n",
      "Feature statistics:\n",
      "       mean radius  mean texture    mean area  mean smoothness  \\\n",
      "count   569.000000    569.000000   569.000000       569.000000   \n",
      "mean     14.127292     19.289649   654.889104         0.096360   \n",
      "std       3.524049      4.301036   351.914129         0.014064   \n",
      "min       6.981000      9.710000   143.500000         0.052630   \n",
      "25%      11.700000     16.170000   420.300000         0.086370   \n",
      "50%      13.370000     18.840000   551.100000         0.095870   \n",
      "75%      15.780000     21.800000   782.700000         0.105300   \n",
      "max      28.110000     39.280000  2501.000000         0.163400   \n",
      "\n",
      "       mean compactness  \n",
      "count        569.000000  \n",
      "mean           0.104341  \n",
      "std            0.052813  \n",
      "min            0.019380  \n",
      "25%            0.064920  \n",
      "50%            0.092630  \n",
      "75%            0.130400  \n",
      "max            0.345400  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Feature Selection - Select 5 features from approved list\n",
    "print('\\nSTEP 2: FEATURE SELECTION')\n",
    "print('='*50)\n",
    "selected_features = ['mean radius', 'mean texture', 'mean area', 'mean smoothness', 'mean compactness']\n",
    "X_selected = X[selected_features]\n",
    "print(f'Selected 5 features: {selected_features}')\n",
    "print(f'Feature matrix shape: {X_selected.shape}')\n",
    "print(f'\\nFeature statistics:\\n{X_selected.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4865f7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 3: TRAIN-TEST SPLIT (BEFORE SCALING - NO LEAKAGE)\n",
      "==================================================\n",
      "Train set size: 455\n",
      "Test set size: 114\n",
      "Train-Test Ratio: 80-20\n",
      "Train target distribution:\n",
      "diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Test target distribution:\n",
      "diagnosis\n",
      "1    72\n",
      "0    42\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 3: CRITICAL - Train/Test Split FIRST (BEFORE scaling) to avoid data leakage\n",
    "print('\\nSTEP 3: TRAIN-TEST SPLIT (BEFORE SCALING - NO LEAKAGE)')\n",
    "print('='*50)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f'Train set size: {X_train.shape[0]}')\n",
    "print(f'Test set size: {X_test.shape[0]}')\n",
    "print(f'Train-Test Ratio: 80-20')\n",
    "print(f'Train target distribution:\\n{y_train.value_counts()}')\n",
    "print(f'Test target distribution:\\n{y_test.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d9e9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 4: FEATURE SCALING (FIT ON TRAINING DATA ONLY)\n",
      "==================================================\n",
      "✓ Feature scaling completed (NO LEAKAGE)\n",
      "Training data shape after scaling: (455, 5)\n",
      "Test data shape after scaling: (114, 5)\n",
      "\n",
      "Scaled training data mean: [-2.92806072e-16  6.24652955e-16 -1.71779562e-16  6.24652955e-17\n",
      " -2.08868332e-16]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Feature Scaling - FIT ONLY ON TRAINING DATA (avoid leakage)\n",
    "print('\\nSTEP 4: FEATURE SCALING (FIT ON TRAINING DATA ONLY)')\n",
    "print('='*50)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit on training data\n",
    "X_test_scaled = scaler.transform(X_test)  # Transform test using training scaler\n",
    "print('✓ Feature scaling completed (NO LEAKAGE)')\n",
    "print(f'Training data shape after scaling: {X_train_scaled.shape}')\n",
    "print(f'Test data shape after scaling: {X_test_scaled.shape}')\n",
    "print(f'\\nScaled training data mean: {X_train_scaled.mean(axis=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5fc14d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 5: MODEL TRAINING\n",
      "==================================================\n",
      "Algorithm: Support Vector Machine (SVM)\n",
      "Kernel: RBF (Radial Basis Function)\n",
      "Probability: True (for confidence scores)\n",
      "✓ SVM model trained successfully\n",
      "Number of support vectors: 111\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Build and Train SVM Model\n",
    "print('\\nSTEP 5: MODEL TRAINING')\n",
    "print('='*50)\n",
    "print('Algorithm: Support Vector Machine (SVM)')\n",
    "print('Kernel: RBF (Radial Basis Function)')\n",
    "print('Probability: True (for confidence scores)')\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "print('✓ SVM model trained successfully')\n",
    "print(f'Number of support vectors: {len(svm_model.support_vectors_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6496b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 6: MODEL EVALUATION\n",
      "==================================================\n",
      "\n",
      "Classification Metrics:\n",
      "  Accuracy:  0.9035\n",
      "  Precision: 0.9552\n",
      "  Recall:    0.8889\n",
      "  F1-Score:  0.9209\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.83      0.93      0.88        42\n",
      "   Malignant       0.96      0.89      0.92        72\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.89      0.91      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39  3]\n",
      " [ 8 64]]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate Model Performance\n",
    "print('\\nSTEP 6: MODEL EVALUATION')\n",
    "print('='*50)\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "y_pred_proba = svm_model.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print('\\nClassification Metrics:')\n",
    "print(f'  Accuracy:  {accuracy:.4f}')\n",
    "print(f'  Precision: {precision:.4f}')\n",
    "print(f'  Recall:    {recall:.4f}')\n",
    "print(f'  F1-Score:  {f1:.4f}')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=['Benign', 'Malignant']))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c89adb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 7: MODEL PERSISTENCE (JOBLIB)\n",
      "==================================================\n",
      "✓ Model saved to: ./breast_cancer_model.pkl\n",
      "✓ Scaler saved to: ./scaler.pkl\n",
      "✓ Selected features saved to: ./selected_features.pkl\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save Model Artifacts using Joblib\n",
    "print('\\nSTEP 7: MODEL PERSISTENCE (JOBLIB)')\n",
    "print('='*50)\n",
    "import os\n",
    "\n",
    "model_dir = './'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_dir, 'breast_cancer_model.pkl')\n",
    "joblib.dump(svm_model, model_path)\n",
    "print(f'✓ Model saved to: {model_path}')\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = os.path.join(model_dir, 'scaler.pkl')\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f'✓ Scaler saved to: {scaler_path}')\n",
    "\n",
    "# Save selected features\n",
    "features_path = os.path.join(model_dir, 'selected_features.pkl')\n",
    "joblib.dump(selected_features, features_path)\n",
    "print(f'✓ Selected features saved to: {features_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05c3c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STEP 8: MODEL RELOADING TEST\n",
      "==================================================\n",
      "✓ Model reloaded successfully\n",
      "✓ Scaler reloaded successfully\n",
      "✓ Selected features reloaded: ['mean radius', 'mean texture', 'mean area', 'mean smoothness', 'mean compactness']\n",
      "\n",
      "Test Prediction:\n",
      "  Predicted class: 0\n",
      "  Confidence: 96.51%\n",
      "  Class probabilities: [0.96507119 0.03492881]\n",
      "✓ Model can be reloaded and used for prediction without retraining\n",
      "\n",
      "==================================================\n",
      "PROJECT COMPLETE - ALL ARTIFACTS SAVED\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Verify Model Reloading and Reusability\n",
    "print('\\nSTEP 8: MODEL RELOADING TEST')\n",
    "print('='*50)\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "loaded_features = joblib.load(features_path)\n",
    "\n",
    "print('✓ Model reloaded successfully')\n",
    "print('✓ Scaler reloaded successfully')\n",
    "print(f'✓ Selected features reloaded: {loaded_features}')\n",
    "\n",
    "# Test prediction with reloaded model\n",
    "test_sample = X_test_scaled[:1]\n",
    "reloaded_pred = loaded_model.predict(test_sample)[0]\n",
    "reloaded_proba = loaded_model.predict_proba(test_sample)[0]\n",
    "confidence = np.max(reloaded_proba) * 100\n",
    "\n",
    "print(f'\\nTest Prediction:')\n",
    "print(f'  Predicted class: {reloaded_pred}')\n",
    "print(f'  Confidence: {confidence:.2f}%')\n",
    "print(f'  Class probabilities: {reloaded_proba}')\n",
    "print('✓ Model can be reloaded and used for prediction without retraining')\n",
    "\n",
    "print('\\n' + '='*50)\n",
    "print('PROJECT COMPLETE - ALL ARTIFACTS SAVED')\n",
    "print('='*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
